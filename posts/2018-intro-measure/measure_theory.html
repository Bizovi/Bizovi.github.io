<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bizovi Mihai">
<meta name="dcterms.date" content="2018-06-01">

<title>Understanding Caratheodori Extension Theorem – {Art, Math, Philosophy}</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/icon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5348f60334dd04cbc36623d8010fff4a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-104200881-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Understanding Caratheodori Extension Theorem – {Art, Math, Philosophy}">
<meta property="og:description" content="{Art, Math, Philosophy}">
<meta property="og:image" content="https://blog.economic-cybernetics.com/posts/2018-intro-measure/img/measure_theory_comics.jpg">
<meta property="og:site_name" content="{Art, Math, Philosophy}">
<meta property="og:locale" content="es_ES">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">{Art, Math, Philosophy}</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../art.html"> 
<span class="menu-text">Paintings</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://course.economic-cybernetics.com/"> <i class="bi bi-journal-bookmark" role="img">
</i> 
<span class="menu-text">Decision-Making</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/bizovi/decision-making"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/bizovi-mihai-56982abb/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Understanding Caratheodori Extension Theorem</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">probability</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Bizovi Mihai </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 1, 2018</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>The reason we need probability theory is that it’s a formal language of uncertainty. Even though you can go a long way as a practitioner with standard tools in probability theory, deeply understanding its <strong>measure-theoretic</strong> foundations could open up a whole new world to the researcher. It’s easy to take the results from statistics and probability for granted, but it’s useful to be aware what hides beneath the surface.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In order to build adequate models of economic and other complex phenomena, we have to take into account their inherent <em>stochastic nature</em>. Data is just the appearance, an external manifestation of some <code>latent processes</code> (seen as random mechanisms). Even though we won’t know the exact outcome for sure, we can model general regularities and relationships as a result of the large scale of phenomena. For more ideas see <span class="citation" data-cites="Ruxanda2011">(<a href="#ref-Ruxanda2011" role="doc-biblioref">Ruxanda 2011</a>)</span></p>
</div></div><p>As an economist and modeler, the goal of this project is to step-by-step explain the <code>Caratheodori Extension Theorem</code> in order to understand the language, gain some intuition and insight about it. The value of studying it comes not from the theorem itself, but from the process of discovery and understanding a proof forces you to go through. <span class="citation" data-cites="Landim2016">(<a href="#ref-Landim2016" role="doc-biblioref">Landim 2016</a>)</span> If you’re a mathematician and for some reason reading this, you might ask:</p>
<blockquote class="blockquote">
<p>“Are you insane going into it without any knowledge of real analysis”?</p>
</blockquote>
<p>The answer is that I want to learn the language, and not to achieve excellence in Measure Theory. Also, I can hardly take things for granted and need a justification of why things (in probability) are done exactly this way. <span class="citation" data-cites="Rosenthal2006">(<a href="#ref-Rosenthal2006" role="doc-biblioref">Rhosental 2006</a>)</span> We’ll develop a plan of attack and a network of ideas and concepts that need to be understood in order to tackle the problem, hoping that resourcefulness and intuitions will compensate for the lack of rigor.</p>
<section id="motivation-for-measure-theory-in-a-practice-oriented-world" class="level2">
<h2 class="anchored" data-anchor-id="motivation-for-measure-theory-in-a-practice-oriented-world">Motivation for measure theory in a practice-oriented world</h2>
<p>The field of Data Mining moved a long way, becoming accessible and bringing value for individuals and industries. A lot of Machine Learning and Statistical models are available with a few lines of code. If it should be obvious why we need probability theory, it’s not so with measure theory.</p>
<blockquote class="blockquote">
<p>See the Andrew Gelan (a giant of Bayesian statistics) and Cosma Shalizi (an expert in Data Mining) disagreement on the <a href="http://andrewgelman.com/2008/01/14/what_to_learn_i/">subject</a></p>
</blockquote>
<p>I’ll give an analogy: even though the models can be easily applied in a high-level language like R or Python, understanding the Learning Theory can bring you on another level, closer to excellence. In the case of measure theory, some argue that there are alternative things to study which can bring more value, and they’re not wrong, but for an ambitious field like Bayesian Nonparametrics, it’s hard to make even little progress because of the understanding barrier. This is why I like to think of it as a language <span class="citation" data-cites="Lawrence2012">(<a href="#ref-Lawrence2012" role="doc-biblioref">Lawrence 2012</a>)</span> extremely useful in the fields of stochastic processes and learning theory. So, the truth is somewhere in between and key to learning these subjects is a personally optimal balance of theoretical understanding, practice on real data problems and simulation exercises.</p>
<p>Studying measure theory might look like a gruesome process to do on your own, but it makes sense posing a reverse question: what do I need to know to understand all these awesome papers where there is a urge to ask: <strong>“The probability over what?”</strong></p>
<blockquote class="blockquote">
<p>A personal experience was in an attempt to study nonlinear state-space models, where there are some exciting papers on Bayesian Nonparametrics and Stochastic Filtering. Reading and working through papers felt like missing a good part of the story, because of some lacking fundamentals. It’s extremely important to recognize what you don’t know. That’s right, I want to be able to formulate meaningful statements about distributions of more abstract objects, like functions, graphs, etc and to reason about stochastic processes.</p>
</blockquote>
<p>For example, having a great understanding of probability helps to define in a clear and rigorous way difficult concepts used in statistics and econometrics (which might look deceptively simple at first) as p-values, confidence intervals, power, hypothesis testing and helps avoiding a lot of confusion. Let’s take the idea of power of the test in its simplest form (for a one-sided Z test), which a lot of practitioners struggle to define when asked.</p>
<blockquote class="blockquote">
<p>The mathematical formulation uncovers some of the assumptions we’re making and suggests the interpretation. Notice how <span class="math display">\[\frac{\mu_a - \mu_0}{\sigma}\]</span> is a proxy for a “unit free” effect size.</p>
</blockquote>
<ul>
<li><span class="math inline">\(\beta\)</span> Type II error: Failure to reject <span class="math inline">\(H_0\)</span> when it’s false</li>
<li><span class="math inline">\(\alpha\)</span> Type I error: Falsely rejecting a true <span class="math inline">\(H_0\)</span></li>
<li><span class="math inline">\(1 - \beta\)</span> is the power</li>
<li><span class="math inline">\(\mu_0\)</span> the null hypothesis</li>
<li><span class="math inline">\(\mu_a\)</span> the alternative hypothesis</li>
</ul>
<p>The response of the power being the probability of rejecting a null hypothesis when it’s false might not suggests that there is much going on.</p>
<p><span class="math display">\[\begin{align*}
    1- \beta &amp;= \mathbb{P} \bigg( \frac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} &gt;
    \mathbf{Z}_{1-\alpha}  \bigg\lvert \mu = \mu_a  \bigg) \\
    ~ &amp;= \mathbb{P} \bigg( \frac{\bar{X} - \mu_a + \mu_a - \mu_0}{\sigma / \sqrt{n}} &gt;
    \mathbf{Z}_{1-\alpha}  \bigg\lvert \mu = \mu_a  \bigg) \\
    ~ &amp;= \mathbb{P} \bigg( \frac{\bar{X} - \mu_a}{\sigma / \sqrt{n}} &gt;
    \mathbf{Z}_{1-\alpha} - \frac{\mu_a - \mu_0}{\sigma / \sqrt{n}} \bigg\lvert \mu = \mu_a  \bigg) \\
    ~ &amp;= \mathbb{P} \bigg( \mathbf{Z} &gt;
    \mathbf{Z}_{1-\alpha} - \frac{\mu_a - \mu_0}{\sigma / \sqrt{n}} \bigg\lvert \mu = \mu_a  \bigg)
\end{align*}\]</span></p>
<p>But there is a lot going on, the power depending on the effect size, assumed level for the type I error and the sample size. The distribution of the term <span class="math display">\[\mathbf{Z} = \frac{\bar{X} - \mu_a}{\sigma / \sqrt{n}}\]</span> is actually the one under the alternative hypothesis. Note that power calculations done post-hoc are usually a terrible idea.</p>
<p>Also, it’s almost impossible to sense the dangers of interpretations of <strong>p-values</strong>, types of errors and <strong>confidence intervals</strong> without trying to understand the mathematics behind statistical testing. Tests are also models, little <strong>“Golemns of the Prague”</strong> and they might fail in unexpected ways when the assumptions do not hold. <span class="citation" data-cites="McElreath">(<a href="#ref-McElreath" role="doc-biblioref">McElreath 2015</a>)</span></p>
<p>As it’s often the case in mathematics, things have a deep justification behind them and even though you can successfully apply the models in practice, understanding is what separates a great modeler. Often, a breakthrough comes in the form of something that nobody have thought before.</p>
<blockquote class="blockquote">
<p>I think we’ll appreciate the input from mathematicians more in an applied field like Data Mining, as it will help figure out why deep neural networks work so well. Same is true for <em>Extreme Gradient Boosting</em> and other things that just seem to work. It took me some time trying to solve real world problems, in order to appreciate the usefulness of deeply understanding different ideas in mathematics.</p>
</blockquote>
<p>This is why, in the path to mastery of machine learning, certain topics appear which might change your perspective forever. One of these is Measure Theory. Is it useful in practice? Probability Theory taught in undergraduate courses might be what most people need, but it’s limited in a certain sense, imposing an <em>artificial dichotomy between discrete and continuous random variables</em> and thinking in terms of probability density functions and cumulative distribution functions.</p>
<p>Regarding (Caratheodori), it’s not the formulation of the theorem which brings the most insight, but ideas in the proof as measurable sets and outer measures.</p>
</section>
<section id="measure-theory-in-machine-learning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="measure-theory-in-machine-learning">Measure Theory in Machine Learning</h2>
<blockquote class="blockquote">
<p>Some courses will mention it, but as a side for the mathematically inclined students and not appearing anywhere later</p>
</blockquote>
<p>In undergraduate probability we can get away with the lack of measure-theoretic notions, as we’re working on real spaces, continuous functions and the instruments we have in these tame cases seem enough. There are also wilder cases, in which we need new tools and language to be rigorous, as otherwise we would just hope for the best (that the probability measure is defined). In some of the fields mentioned above researchers have to deal with weird stuff like distributions which have continuous and discrete elements, when a mixture of a density with point masses isn’t very helpful to work with.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="img/measure_theory_comics.jpg" class="img-fluid"> Source: <a href="http://brownsharpie.courtneygibbons.org">brownsharpie</a></p>
</div></div><p>Evans Lawrence gives the following example of a function which is neither discrete nor continuous, for which you flip a coin and if it comes heads, draw from an uniform distribution and in case of tails a unit mass at one. If <span class="math inline">\(\chi_{[0,1]}(x) = (e^{ix} - 1)/ix\)</span> is the characteristic function of the interval from zero to one, in a way you can formulate its density, but usually it’s not the case, nor is it very helpful to think about it in such terms.</p>
<p><span class="math display">\[\begin{equation}
    p(x) = w_1 \chi_{[0,1]}(x) +  w_2\delta_1(x)
\end{equation}\]</span></p>
<p>Even though you can visualize this in two dimensions as the uniform and a spike, or as a CDF with a discontinuity, this approach just breaks down in higher dimensions or more complicated combinations of functions.</p>
<p>Jeffrey Rosenthal begins his book <span class="citation" data-cites="Rosenthal2006">(<a href="#ref-Rosenthal2006" role="doc-biblioref">Rhosental 2006</a>)</span> by a similar motivation, constructing the following random variable as a coin toss between a discrete <span class="math inline">\(X \sim Pois(\lambda)\)</span> and continuous <span class="math inline">\(Y \sim \mathcal{N}(0,1)\)</span> r.v.</p>
<p><span class="math display">\[\begin{equation}
    Z = \begin{cases}
    X, p = 0.5 \\
    Y, p = 0.5
    \end{cases}
\end{equation}\]</span></p>
<p>He then challenges the readers to come up with the expected value <span class="math inline">\(\mathbb{E}[Z^2]\)</span> and asks on what is it defined? It is indeed a hard question.</p>
<p>It is not surprising for me that measure theory becomes important in the Learning Theory, even though lighter courses from which I studied don’t mention it explicitly (Yaser Abu-Mostafa, Shai Ben-David, Reza Shadmehr). According to Mikio’s Brown <a href="https://www.quora.com/Is-Measure-Theory-relevant-to-Machine-Learning/answer/Mikio-L-Braun?srid=KONR">answer</a> it’s essential in the idea of <strong>uniform convergence</strong> and its bounds, where <em>“you consider the probability of a supremum over an infinite set of functions, but out of the box measure theory only allows for constructions with countably infinite index sets”</em>.</p>
<p>If we’re thinking about a regression from the nonparametric perspective <span class="math inline">\(f(x) \in \mathscr{C}^2:X \rightarrow \mathbb{R}\)</span>, we might want to know how a draw from a (infinite) set of continuous differentiable functions might look like. The questions arises: how to define a PDF in this space? In my thesis <span class="citation" data-cites="Bizovi">(<a href="#ref-Bizovi" role="doc-biblioref">Mihai 2017</a>)</span> I got away with using Gaussian Processes, which are a very special class of stochastic processes. In this special case I could informally define an apriori distribution by defining the mean vector and Kernel (covariance function), then condition it on observed data with a Normal Likelihood.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="img/prior.png" class="img-fluid"> An example of reasoning about distributions of random functions from my Thesis. The prior distribution</p>
</div><div class="">
<p><img src="img/conditionare_gp.png" class="img-fluid"> Only the functions that explain the data well survive</p>
</div></div>
<p><span class="math display">\[\begin{equation}
p(f(x) \, |\left \{ x\right \})=\frac{p(\left \{ x\right \}| \, f) \, \mathbf{p(f)}}{p(\left \{ x\right \})}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation*}
f(x) \sim GP(\mu(x); K(x,x'))
\end{equation*}\]</span></p>
<p>The result was that only the functions that explained the data well survived. While this reasoning makes intuitive sense, there are things “swiped under the carpet”. If we were to model stock prices, where there are jumps and the process itself is less smooth, measure theory would be very hard to avoid. If we would want to reason in terms of densities, ask with respect to what? So, the focus is shifted towards the question of what is the probability of every possible event. This leads us back to the fundamental object of state (outcome) space <span class="math inline">\(\mathbf{\Omega}\)</span>.</p>
<blockquote class="blockquote">
<p>Each element <span class="math inline">\(\omega_i \in \mathbf{\Omega}\)</span> is an elementary event (outcome), while <span class="math inline">\(A \subset \mathbf{\Omega}\)</span> is an event</p>
</blockquote>
<p>As we will shortly see, it’s impossible to define the probability (measure) on the set of all subsets <span class="math inline">\(2^\Omega\)</span>, except for the simple finite cases, without having to let go of a fundamental axiom like countable additivity. This will be the first step in getting closer to defining a Uniform distribution on <span class="math inline">\([0, 1]\)</span>.</p>
<blockquote class="blockquote">
<p>Surprisingly, to rigorously define an Uniform distribution is not a trivial task, because of the mentioned above impossibility, proved later by contradiction. In contrast, Caratheodori theorem allows us to do exactly that</p>
</blockquote>
<p>Tarun Chitra in the same thread argues that many classification problems are ill-posed mathematically, and the ones which can be formulated in a measure-theoretic way have very nice results, like SVMs with Reproducing Kernel Hilbert Spaces, where you cannot apply the Mercer’s Theorem unless the Kernel is measurable. The second example he gives is proving some results about Stochastic Gradient Descent, an optimization algorithm often successfully used, which has connection with Brownian Motion, thus Weiner measures.</p>
<p>Measure theory is also important in rigorously defining distances and divergences (for example between two distributions as in Kullback-Leiber)</p>
</section>
<section id="measure-theory-and-the-fundamentals-of-probability-theory" class="level2">
<h2 class="anchored" data-anchor-id="measure-theory-and-the-fundamentals-of-probability-theory">Measure Theory and the fundamentals of Probability Theory</h2>
<p>It is useful to step back and see where does Measure Theory fit in the framework of Probability Theory. The following list will be a summary of a lecture at doctoral school by <span class="citation" data-cites="Ruxanda2017">(<a href="#ref-Ruxanda2017" role="doc-biblioref">Ruxanda 2017</a>)</span> Here are 8 steps to mastery of the basics by Gheorghe Ruxanda:</p>
<ol type="1">
<li>A <strong>random experiment</strong> (<span class="math inline">\(\mathscr{E}\)</span>) is a set of <em>conditions which are favorable for an event</em> in a given form with the following properties:
<ul>
<li>Possible results are known apriori</li>
<li>It’s never known which of the results of <span class="math inline">\(\mathscr{E}\)</span> will exactly appear</li>
<li>Despite (b), <strong>there is a perceptible regularity</strong>, (encoding the idea of a probabilistic “law”) in the results. Also, it could be as a result of the large scale of the phenomena.</li>
<li>Repeatability of the conditions, i.e.&nbsp;the comparability and perservation of context are key.</li>
</ul></li>
<li><strong>Elementary event</strong> as an auxiliaty construction: one of the possible results of <span class="math inline">\(\mathscr{E}\)</span>, <span class="math inline">\(\omega_i \in \Omega\)</span></li>
<li><strong>Universal set</strong> <span class="math inline">\(\Omega = \{ \omega_1, \omega_2, \dots \}\)</span> Also called (Outcome/ State/ Selection space), it suggests the idea of complementarity and stochasticity: we don’t know which <span class="math inline">\(\omega_i\)</span>, is a key object for a further formalization of probability measures.</li>
<li>We care not only about <strong>an event</strong> <span class="math inline">\(A = \bigcup\limits_{i = 1}^n \omega_i\)</span> and its realization, but also about other events in the Universal Set, because they might add information about the probability of occurring of our event of interest</li>
<li>The <strong>event space</strong> <span class="math inline">\(\mathcal{F}\)</span> should be defined on sets of subsets of <span class="math inline">\(\Omega\)</span> and this is where measure theory shines. We’ll discuss later in extensive detail the following conditions on the way to defining sigma-algebras. As can be seen later, we usually can’t define a probability measure on all sets of subsets.</li>
<li><strong>Probability as an extension of the measure</strong>: chance of events realizing. Note that the perceptible regularity can be thought as the ability to assign a probability to elementary events: <span class="math inline">\(\mathbb{P}(\omega_i)\)</span>. This is where additivity properties are key. A long discussion on Frequentist vs Bayesian interpretation of it can follow from here.</li>
<li>A <strong>probability triple</strong> <span class="math inline">\((\Omega, \mathcal{F}, \mathbb{P})\)</span></li>
<li>The idea of <strong>Random Variable</strong></li>
</ol>
<p>Before moving on to probability measures, it’s useful to think about what a random variable really is and does, because formally, it’s neither a variable, nor random. That should be another motivation for speaking the language of measure theory.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/random_variable.png" class="img-fluid figure-img"></p>
<figcaption>Idea: Norman Wildberger, Gheorghe Ruxanda. A graphical representation of the random variable</figcaption>
</figure>
</div>
<p>The idea of the random variable as being a quantificator of elementary events (function defined on the outcome space which maps the elementary events to the real line in 1d) that perserves the informational structure of the sample space is very powerful, is formally defined and related to the idea of <strong>measurability</strong>.</p>
<blockquote class="blockquote">
<p>Start from some phenomena of interest and a random experiment. The random variable is a necessary abstraction in order to mathematically define quantificable characteristics of the objects.</p>
</blockquote>
<p><span class="math display">\[\begin{align}
X(\omega):\Omega \rightarrow \mathbb{R} \\
s.t. ~~ \{\omega \in \Omega | X(\omega) \leq r, \forall r \in \mathbb{R} \} \in \mathcal{F}
\end{align}\]</span></p>
<p>The idea of conservation of the informational structure is actually equivalent to the one of measurablility. If this property doesn’t hold, it’s not possible to explicitly and uniquely refer to the sets (events) of interest. The idea is that the preimage defined above <span class="math inline">\(X^{-1}((-\infty,r]) = E \in \mathcal{F}\)</span> on the following interval corresponds to an event E which should be in the event space <span class="math inline">\(\mathcal{F}\)</span>. Because the only thing that varies is the limit of the interval r, the randomness comes from it. Also, it automatically suggests the idea of the Cumulative Distribution Function, which is <span class="math inline">\(F_X(X \le r)\)</span>.</p>
</section>
<section id="cant-have-it-all-the-trouble-with-the-uniform" class="level2">
<h2 class="anchored" data-anchor-id="cant-have-it-all-the-trouble-with-the-uniform">Can’t have it all: The trouble with the Uniform</h2>
<p><strong>Following the previous discussions</strong> we would want to define a probability measure <span class="math inline">\(\mathbb{P} :2^\Omega \rightarrow [0, 1]\)</span> on the set of all subsets of <span class="math inline">\(\Omega = [0, 1]\)</span> for the uniform distribution. Unfortunately we can’t have that <strong>and</strong> perserve essential properties of probability measures.</p>
<blockquote class="blockquote">
<p>All other properties can be easily derived from these, thus these are minimal requirements for a probability measure. Nonetheless, these conditions are too restrictive if we want to define an Uniform Distribution on <span class="math inline">\(2^\Omega\)</span>.</p>
</blockquote>
<ol type="1">
<li><span class="math inline">\(\mathbb{P}(\Omega) = 1\)</span> and <span class="math inline">\(\mathbb{P}(\varnothing) = 0\)</span></li>
<li><span class="math inline">\(\mathbb{P}(A) \in [0, 1]\)</span></li>
<li>If <span class="math inline">\(A \cap B = \varnothing \implies  \mathbb{P}( A \cap B) =  \mathbb{P}(A) + \mathbb{P}(B)\)</span></li>
<li>If <span class="math inline">\(\{ A_i \}_{i=1}^\infty\)</span> s.t. <span class="math inline">\(A_i \bigcap\limits_{i \ne j} A_j = \varnothing \implies \mathbb{P} ( \bigcup\limits_{i = 1}^\infty A_i) = \sum\limits_{i = 1}^{\infty}\mathbb{P}(A_i)\)</span></li>
</ol>
<p>The idea of uniform distribution is closely related to the one of <strong>length</strong>, area, volume, depending on what space are we into. That means the probability measure will look like this:</p>
<p><span class="math display">\[\begin{equation}
    \mathbb{P}([a, b]) = b - a
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathbb{P} :2^\Omega \rightarrow [0, 1]\)</span> and <span class="math inline">\(0 \le a \le b \le 1\)</span></p>
<p>The proof is done by contradiction, but the implications are a little bit deeper, related to paradoxes like <strong>Banakh-Tarsky</strong> and <strong>Vitali Sets</strong>, which are counter-intuitive but closely related to the idea of something being unmeasurable. Because we can’t get rid of any of the axioms, we should deal with the fact that we can’t define the measure on <span class="math inline">\(2^\Omega\)</span>.</p>
<p>Instead define a set of subsets <span class="math inline">\(\mathcal{A} \subset 2^\Omega\)</span> such that <span class="math inline">\(\mathbb{P}: \mathcal{A} \rightarrow [0,1]\)</span>. These sets will have to obey certain properties and this is where all the terminology from measure theory comes in with algebras, semi-algebras and sigma-algebras. Each of these concepts and objects will be stepping stones towards understanding Caratheodori</p>
</section>
<section id="background-concepts-towards-caratheodori" class="level2">
<h2 class="anchored" data-anchor-id="background-concepts-towards-caratheodori">Background concepts towards Caratheodori</h2>
<p>Let’s continue on this upbeat note and try to figure out what kind of sets <span class="math inline">\(\mathcal{A}\)</span> are measurable, for which we can define their probabilities.</p>
<p><strong>Def: Algebra and Semi Algebra:</strong> A set of subsets <span class="math inline">\(\mathcal{A} \subset 2^\Omega\)</span> is an algebra (field) if the following holds:</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathcal{A}\)</span> and <span class="math inline">\(\varnothing \in \mathcal{A}\)</span></li>
<li>If <span class="math inline">\(A \in \mathcal{A}\)</span> then <span class="math inline">\(A^C \in \mathcal{A}\)</span> (closed under complements)</li>
<li>If <span class="math inline">\(A, B \in \mathcal{A}\)</span> then $ A B $ (closed under union). Note that 2 and 3 imply that it’s closed under countable intersection</li>
<li>For sigma-algebra: <strong>sigma</strong> refers to countability} If <span class="math inline">\(\{  A_i \}_{i \ge 1} \in \mathcal{A}\)</span> then <span class="math inline">\(\bigcup\limits_{i \ge 1} A_i \in \mathcal{A}\)</span> (closed under <strong>countable union</strong>)</li>
</ol>
<p>On an intuitive note, we define the probability measure on sigma-algebras because if certain conditions did not hold, the measure wouldn’t make sense.</p>
<p><strong>Def: Probability Measure:</strong> Suppose we have defined a <strong>measurable space</strong> <span class="math inline">\((\Omega, \mathcal{A})\)</span>, where <span class="math inline">\(\mathcal{A}\)</span> is a sigma-algebra. A <strong>probability measure</strong> is the function <span class="math inline">\(\mathbb{P}:\mathcal{A} \rightarrow [0, 1]\)</span> such that:</p>
<ol type="1">
<li><span class="math inline">\(\mathbb{P}(\Omega) = 1\)</span> </li>
<li><span class="math inline">\(\forall \{ A_i \}_{i \ge 1}\)</span> where <span class="math inline">\(A_i \bigcap\limits_{i \ne j} A_j = \varnothing\)</span> (countable sequences of mutually disjoint effects), <span class="math inline">\(\mathbb{P}(\bigcup\limits_{i \ge 1} A_i) = \sum\limits_{i \ge 1} \mathbb{P}(A_i)\)</span></li>
</ol>
<p>As stated earlier, for more difficult cases, when it’s hard or impossible to reason in terms of probability density functions, it is more convenient to talk about measures. For the previous cases of point masses <span class="math inline">\(\delta_k(x)\)</span> and continuous functions we can ask the question what is the probability of a certain outcome directly if using measure-theoretic formalism. <span class="math inline">\(\Omega = \mathbb{R}\)</span> and <span class="math inline">\(\mathcal{A} = 2^\Omega\)</span> and the point mass looks basically like a spike at <span class="math inline">\(k^{th}\)</span> place in the real line.</p>
<p><span class="math display">\[\begin{equation}
    \mathbb{P}(A) = \begin{cases}
    1, ~~ k \in A\\
    0, ~~ k \notin A
    \end{cases}
\end{equation}\]</span></p>
<p>In order to define the probability measure for the continuous measure, much deeper results should be invoked. &gt; The Borel Spaces in itself encode a chain of new concepts that need to be understood from Banakh Spaces, Normed Spaces and how to close them under complement and union.</p>
<ol type="1">
<li><span class="math inline">\(\Omega = \mathscr{C}([0,1];\mathbb{R})\)</span></li>
<li><span class="math inline">\(\mathcal{A} = \mathcal{B}(\mathscr{C}([0,1];\mathbb{R}))\)</span></li>
</ol>
<p>This might be one of the reasons why Stochastic Processes is such a difficult and powerful field, because of the amount of knowledge encoded even in the “simplest” Brownian Motion (where <span class="math inline">\(\mathbb{P}\)</span> is a Weiner measure).</p>
<p>Going back to our pursuit of Caratheodori theorem, it is useful to understand why do we need countable additivity. If the finite additivity is clear, for example in the case of disjoint segments of the uniform distribution <span class="math inline">\(X \sim Unif([0,1])\)</span>, <span class="math inline">\([a_1, b_1]\)</span> and <span class="math inline">\([a_2, b_2]\)</span>, it’s essential that the following holds.</p>
<p><span class="math display">\[
\mathbb{P}([a_1, b_1] \cup [a_2, b_2] ) = \mathbb{P}(a_1 \le X \le b_1) + \mathbb{P}(a_2 \le X \le b_2)
\]</span></p>
<p>Countable additivity <span class="math inline">\(\mathbb{P}(\bigcup\limits_{i \ge 1} A_i) = \sum\limits_{i \ge 1} \mathbb{P}(A_i)\)</span> is useful to prove that limits exists, which is very important in various statistical procedures. We can’t say anything about uncountable additivity because the measure of each element on the r.h.s. will be zero, while the measure of the interval is one, which is a contradiction</p>
<p>To get our feet wet, let’s see what techniques are employed by various authors in order to prove the impossibility of constructing a measure which has the idea of length while keeping the axioms.</p>
<p><strong>Proposition:</strong> There does not exist a (probability) measure <span class="math inline">\(\lambda(A)\)</span> <em>(Note that we’ll switch conventions to the measure-theoretic one employed by the Claudio Landim’s course as it’s one of the very few available online and it should be easier to follow in parallel with this reading)</em> defined for all subsets of <span class="math inline">\(A \subseteq [0, 1]\)</span> satisfying.</p>
<ol type="1">
<li><span class="math inline">\(\lambda: \mathscr{P}([0,1]) \rightarrow [0,1]\)</span> which could be all rational numbers, for example</li>
<li><span class="math inline">\(\lambda([a, b])  = b - a\)</span> as an extension of the idea of length</li>
<li><span class="math inline">\(\forall A \subseteq [0,1]\)</span> and <span class="math inline">\(\forall x \in [0,1]\)</span> translation invariance <span class="math inline">\(\lambda(A + x)  = \lambda(A)\)</span>. Alternatively stated, <span class="math inline">\(A + x = \{x + y ~|~ y \in A \}\)</span>.</li>
<li>If <span class="math inline">\(A = \bigcup\limits_{j \ge 1} A_j\)</span> is an union of mutually disjoint sets <span class="math inline">\(A_i \cap A_j = \varnothing\)</span> then <span class="math inline">\(\lambda(A) = \sum\limits_{j \ge 1} \lambda(A_j)\)</span> This is exactly the notion of sigma-additivity encontered over and over again.</li>
</ol>
<blockquote class="blockquote">
<p>We can use <span class="math inline">\([0, 1]\)</span> as in Rosenthal without loss of generality. Landim uses <span class="math inline">\(\mathbb{R}_+\cup\{ +\infty \}\)</span>. Note that <span class="math inline">\(\mathscr{P}(\cdot)\)</span> is the power set}</p>
</blockquote>
<p><strong>Proof:</strong> Assume that <span class="math inline">\(\exists\)</span> a measure <span class="math inline">\(\lambda\)</span> such that above conditions hold. First, we need to introduce the notion of equivalence relation (in order to say “x is related to y”: <span class="math inline">\(x \sim y\)</span>), which is key to proving this. The point is that the equivalence relation will partition a set, which allows us by invoking the Axiom of Choice to get towards the desired contradiction.</p>
<blockquote class="blockquote">
<p><strong>Relation set</strong>: S is a boolean function with <span class="math inline">\(x, y \in S\)</span> <span class="math display">\[R:S \times S \rightarrow \{0, 1\}\]</span> Thus <span class="math inline">\(x \sim y\)</span> means x is <strong>related to</strong> y.</p>
</blockquote>
<p>Given an equivalence relation ~ and <span class="math inline">\(x \in S\)</span> the <strong>equivalence class</strong> of x is <span class="math inline">\(\{ y \in S \lvert y \sim x  \}\)</span>. If x is an equivalence class then any pair of equivalence classes is either identical or disjoint. So, the relation forms equivalence classes, which form a partition on S.</p>
<p><strong>Def:</strong> A relation is an equivalence relation if</p>
<ul>
<li>reflexive: <span class="math inline">\(x \sim x\)</span> <span class="math inline">\(~~ \forall x \in S\)</span></li>
<li>symmetric: <span class="math inline">\(x \sim y \implies y \sim x\)</span> <span class="math inline">\(~~ \forall x, y \in S\)</span></li>
<li>tranzitive: <span class="math inline">\(x \sim y\)</span> and <span class="math inline">\(y \sim z  \implies x \sim z\)</span> <span class="math inline">\(~~ \forall x, y, z \in S\)</span></li>
</ul>
<p>Both Rosenthal and Landim use a special equivalence class involving a relation <span class="math inline">\(x \sim y\)</span>, <span class="math inline">\(x, y \in \mathbb{R}\)</span> for rational numbers: <span class="math inline">\(y - x \in \mathbb{Q}\)</span>. The equivalence class for x becomes</p>
<p><span class="math display">\[\begin{align}
    [x] = \{ y \in \mathbb{R} | y - x \in \mathbb{Q} \} \\
     \Lambda = \{ \alpha, \beta \dots \} = \mathbb{R} \lvert \sim
\end{align}\]</span></p>
<p><span class="math inline">\(\Lambda\)</span> is another important object (the set of equivalence classes) which is R modulo the equivalence relation, clearly uncountable, because <span class="math inline">\([x]\)</span> are countable. Now, using the Axiom of Choice a new set <span class="math inline">\(\Omega\)</span> is constructed in the following way: for each equivalence class <span class="math inline">\(\alpha, \beta\)</span> <strong>one</strong> and only one element is selected.</p>
<blockquote class="blockquote">
<p>There are deep philosophical discussions regarding it, but it’s outside the scope of current project. Basically what we need to know is that it allows us to “simultaneously” choose from <span class="math inline">\(\Lambda_j\)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/transition.png" class="img-fluid figure-img"></p>
<figcaption>A graphical representation assuming the Axiom of Choice.</figcaption>
</figure>
</div>
<p><span class="math inline">\([x]\)</span> can be chosen in such a way that <span class="math inline">\(\Omega \in [0, 1]\)</span></p>
<p>We reached a little milestone, as now there is a handle and structure to the problem, in contrast it wasn’t clear where to start from in the beginning. Here, Rosenthal is very brief, finishes the proof quickly and it seems that Landim chooses a much longer, but much more explicit way. A link to the alternative <a href="https://www.youtube.com/watch?v=qaCOTKh8o4w">proof</a>. I’ll choose the first one, because there are not many concepts used later for us to benefit by going through it.</p>
<p><span class="math display">\[\begin{equation}
    \Omega = \{ \omega_1 \in \alpha , \omega_2 \in \beta, \dots  \} \in [0, 1]
\end{equation}\]</span></p>
<p>A key claim is that if we translate <span class="math inline">\(\Omega\)</span> by <span class="math inline">\(p, q \in \mathbb{Q}\)</span>, the following dichotomy is true: either the sets are equal or disjoint (which was mentioned at the beginning of the proof). </p>
<p><span class="math display">\[\begin{equation}
\begin{cases}
    \Omega + q = \Omega + p   \\
    (\Omega + q) \cap (\Omega + p) = \varnothing
    \end{cases}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(\Omega\)</span> contains an element from each equivalence class, each point in <span class="math inline">\((0, 1] \subseteq \bigcup\limits_{r \in \mathbb{Q}} (\Omega + r)\)</span> (is contained in the union of rational shifts of <span class="math inline">\(\Omega\)</span>).</p>
<p>Since <span class="math inline">\(\Omega\)</span> has only one element <span class="math inline">\(\forall [x] \implies \Omega + r, \forall r \in [0, 1]\)</span> are disjoint. Thus for <span class="math inline">\(r \in [0, 1]\)</span>,</p>
<p><span class="math display">\[\begin{align}
    \lambda([0, 1]) &amp;= \sum\limits_{r \in \mathbb{Q}} \lambda(\Omega + r) \\
    &amp;= \sum\limits_{r \in \mathbb{Q}} \lambda(\Omega)
\end{align}\]</span></p>
<p>Notice the rhs is countably infinite sum, so it can be either zero or <span class="math inline">\(+\infty\)</span> or <span class="math inline">\(-\infty\)</span>, but lhs is one. So, we arrive at the contradiction. For the last steps, some more understanding is needed. This is why the second proof is great and even though longer, very explicit.</p>
<p>So, what’s the trouble with the Uniform? Nothing particular, it’s just that not all subsets are measurable (have an associated measure). This is why we need concepts like semi-algebra, algebra and sigma-algebra in order to reason about what subsets of the power set are measurable.</p>
</section>
<section id="plan-of-attack" class="level2">
<h2 class="anchored" data-anchor-id="plan-of-attack">Plan of Attack</h2>
<p><strong>The idea</strong> is to extend the following measure <span class="math inline">\(\lambda([a, b]) = b - a\)</span> (of the length) to increasingly more strict scope with respect to <span class="math inline">\(\mathscr{P}(\mathbb{R})\)</span>, while keeping the desired properties. I jumped a little bit ahead of myself defining the sigma-algebra, as there are more prerequisites and intermediary steps needed. Defining the following objects (<strong>classes of subsets</strong>) will help demistify a lot of terminology used</p>
<ul>
<li>semi-algebra</li>
<li>algebra</li>
<li>sigma-algebra</li>
</ul>
<p>We’ll construct an increasing set of more restrictive conditions. Basically, semi-algebra is weaker than algebra which is weaker than sigma-algebra. These classes of subsets have certain properties and subtle relationships between them and without understanding these, it is very hard to move on to extend the measure.</p>
<p><strong>Def:</strong> Semi-Algebra is a class of subsets <span class="math inline">\(\mathcal{S} \subseteq \mathscr{P}(\Omega)\)</span> if the following holds</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathcal{S}\)</span> and <span class="math inline">\(\varnothing \in \mathcal{S}\)</span></li>
<li><span class="math inline">\(A, B \in \mathcal{S} \implies A \cap B \in \mathcal{S}\)</span> (closed by finite intersections)</li>
<li><span class="math inline">\(\forall A \in \mathcal{S}\)</span>, <span class="math inline">\(\exists \{ E_1 , \dots, E_n \} \implies A^C = \sum\limits_{j = 1}^n E_j\)</span> Complement viewed as a finite union of elements of <span class="math inline">\(\mathcal{S}\)</span></li>
</ol>
<p>Imagine a segment <span class="math inline">\([a, b]\)</span> on <span class="math inline">\([0, 1]\)</span> and take its complement, it is obvious that it can be represented as a finite union of sets of <span class="math inline">\(\mathcal{S}\)</span>. Actually, these simple examples inspired the definition of semi algebra, but as we can see the conditions are weaker than the ones for algebra. The algebra and sigma-algebra were defined above, but it doesn’t hurt to inspect the relationship between the two in more detail.</p>
<p><strong>Def:</strong> Algebra is a class of subsets <span class="math inline">\(\mathcal{A} \subseteq \mathscr{P}(\Omega)\)</span> if the following holds</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathcal{A}\)</span> and <span class="math inline">\(\varnothing \in \mathcal{A}\)</span></li>
<li><span class="math inline">\(A, B \in \mathcal{A} \implies A \cap B \in \mathcal{A}\)</span> (closed by finite intersections)</li>
<li><span class="math inline">\(A \in \mathcal{A} \implies A^C \in \mathcal{A}\)</span> (closed under complements, a stronger condition)</li>
</ol>
<p><strong>Remark:</strong> If <span class="math inline">\(\mathcal{A}\)</span> is a sigma-algebra then <span class="math inline">\(\mathcal{A}\)</span> is also a semi-algebra. This is important because we want to make statements about algebras generated by semi-algebras which have very nice properties.</p>
<p><strong>Remark:</strong> Let <span class="math inline">\(\mathcal{A}_i \subseteq \mathscr{P}(\Omega)\)</span> be an algebra of subsets of <span class="math inline">\(\Omega\)</span> where <span class="math inline">\(i \in I\)</span> could be any index. Then <span class="math inline">\(\bigcap\limits_{i \in I} \mathcal{A}_i = \mathcal{A}\)</span> is also an algebra. This is verified by the definition of algebra.</p>
<p><strong>Def:</strong> Sigma-Algebra is a class of subsets <span class="math inline">\(\mathcal{F} \in \mathscr{P}(\Omega)\)</span> if the following holds</p>
<ol type="1">
<li><span class="math inline">\(\Omega \in \mathcal{F}\)</span> and <span class="math inline">\(\varnothing \in \mathcal{F}\)</span></li>
<li><span class="math inline">\(A_j \in \mathcal{F}\)</span> <span class="math inline">\(\implies \bigcap\limits_{j \ge 1} A_j \in \mathcal{F}\)</span> (closed by <strong>countable</strong> intersections)</li>
<li><span class="math inline">\(A \in \mathcal{F} \implies A^C \in \mathcal{F}\)</span> (closed under complements)</li>
</ol>
<p><strong>Remark:</strong> Let <span class="math inline">\(\mathcal{F}_i \in \mathscr{P}(\Omega)\)</span> be a sigma-algebra of subsets of <span class="math inline">\(\Omega\)</span> where <span class="math inline">\(i \in I\)</span> could be any index. Then <span class="math inline">\(\bigcap\limits_{i \in I} \mathcal{F}_i = \mathcal{F}\)</span> is also an algebra. Same as in case of algebra</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/extension.png" class="img-fluid figure-img"></p>
<figcaption>The plan of attack. A sigma-additive measure defined on semi-algebra is extended to the algebra generated by the semi-algebra. The latter in turn is extended by Caratheodori theorem to the sigma-additive measure defined on sigma-algebra generated by the semi-algebra</figcaption>
</figure>
</div>
<p>Also needs to be shown that these extensions are unique at each step. Let’s take a break in order not to get lost in detail and terminology: What are we doing here? It was proven that we cannot define a measure extending the idea of length on <span class="math inline">\(\mathscr{P}(\Omega)\)</span> under standard axioms of probability.</p>
<p><span class="math inline">\(\Omega = [0, 1], \mathbb{P}([a, b]) = b - a\)</span>, but what is <span class="math inline">\(\mathcal{F}\)</span>? A sigma-algebra, but it’s not obvious at all why.</p>
<p><span class="math display">\[\begin{equation}
    Unif([0, 1]) \longrightarrow (\Omega, \mathcal{F}, \mathbb{P})
\end{equation}\]</span></p>
<p>That gave a motivation of defining measures on <strong>algebras</strong> with conditions of ever increasing strength/restriction. Relationships between these types of objects and their properties are key in making progress, which is quite clear from the diagram above. Even though these steps might look similar, the techniques and concepts employed are quite different. Nonetheless, the question always stays conceptually the same: On what can we define a (probability) measure? In essence, the whole language is developed in order to reason and make meaningful statements about sets of subsets and whether it can be “measured”.</p>
<blockquote class="blockquote">
<p>Also notice that we haven’t still reached even the start of what most measure-theoretic probability courses begin from. This is good, because we’re spending time on understanding the fundamentals on which all that theory is built.</p>
</blockquote>
<p>The next element we need is to define relationships between fields such as algebras generated by semi-algebras and so on. First, C. Landim introduces an algebra <span class="math inline">\(\mathcal{A}(\mathscr{C})\)</span> generated by a class of sets <span class="math inline">\(\mathscr{C} \subseteq \mathscr{P}(\Omega)\)</span> such that the following holds</p>
<ol type="1">
<li><span class="math inline">\(\mathscr{C} \subseteq \mathcal{A}\)</span>, where <span class="math inline">\(\mathcal{A}\)</span> is the smallest algebra that contains <span class="math inline">\(\mathscr{C}\)</span></li>
<li>If <span class="math inline">\(\mathscr{B} \supseteq \mathscr{C}\)</span> is a sigma-algebra <span class="math inline">\(\implies \mathscr{B} \supseteq \mathcal{A}\)</span></li>
</ol>
<p>Remarkably, the same is true for sigma-algebras, proven by a chain of thought involving all sets <span class="math inline">\(\mathcal{A}_\alpha\)</span> which contain <span class="math inline">\(\mathscr{C}\)</span>. Their intersection <span class="math inline">\(\bigcap\limits_\alpha \mathcal{A}_\alpha  = \mathcal{A}\)</span> contains <span class="math inline">\(\mathscr{B}\)</span> and since it contains $ $, it belongs to that intersection, hence, it’s the smallest sigma-algebra that contains <span class="math inline">\(\mathscr{C}\)</span>.</p>
<p>If the underlying class <span class="math inline">\(\mathscr{C}\)</span> is a semi-algebra, then <span class="math inline">\(\mathcal{A}(\mathscr{C})\)</span> has an explicit form as a finite union of elements of semi-algebra. In the case of sigma-algebras, other techniques and arguments are needed because we don’t have such a form, which will be a major blocker.</p>
<ol type="1">
<li>Prove and formalize the last statement about sigma-algebras generated by semi-algebras</li>
<li>Explore additivity in measure functions</li>
<li>Explore sigma-additivity in measure functions</li>
<li>Understand Continuity from Above and Below and its connections with additivity</li>
<li>Extend the measure defined by semi-algebra on sigma-algebra generated by semi-algebra. Prove uniqueness</li>
</ol>
<p><strong>Theorem:</strong> (Caratheodori) Let <span class="math inline">\(\mathcal{F}(\Omega)\)</span> be a semi-algebra of subsets of <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\pi: \mathcal{F} \rightarrow [0, 1]\)</span> with <span class="math inline">\(\pi(\varnothing) = 0\)</span> and <span class="math inline">\(\pi(\Omega) = 1\)</span> satisfying the superadditivity property:</p>
<ol type="1">
<li><p><span class="math inline">\(\pi(\bigcup\limits_{i = 1}^k A_i) \ge \sum\limits_{i = 1}^k \pi(A_i)\)</span> where <span class="math inline">\(A_i \in \mathcal{F}\)</span> and <span class="math inline">\(\bigcup\limits_{i = 1}^k A_i \in \mathcal{F}\)</span> disjoint.</p></li>
<li><p><span class="math inline">\(\pi(A) \le \sum\limits_n \pi(A_n)\)</span> where <span class="math inline">\(A_i \in \mathcal{F}\)</span> and <span class="math inline">\(A \in \bigcup\limits_n A_n\)</span></p>
<p>Then <span class="math inline">\(\exists\)</span> a sigma-algebra <span class="math inline">\(\mathcal{M} \supseteq \mathcal{F}\)</span> and a countably additive probability measure <span class="math inline">\(\pi^*:\mathcal{M}\rightarrow [0, 1]\)</span> such that <span class="math inline">\(\pi^*(A) = \pi(A) ~~ \forall A \in \mathcal{F} \implies (\Omega, \mathcal{F},  \pi^*)\)</span> is a valid probability triple, which agrees with previous probabilities on <span class="math inline">\(\mathcal{F}\)</span> <span class="citation" data-cites="Rosenthal2006">(<a href="#ref-Rosenthal2006" role="doc-biblioref">Rhosental 2006</a>)</span></p></li>
</ol>
</section>
<section id="proof-left-as-an-exercise-just-kidding" class="level2">
<h2 class="anchored" data-anchor-id="proof-left-as-an-exercise-just-kidding">Proof Left as an Exercise [Just Kidding]</h2>
<p>We’re middle way through and already discovered a lot of insights, but there are more things to be done:</p>
<ol type="1">
<li>Define and understand the concept of outer measure</li>
<li>Prove that <span class="math inline">\(\mathcal{M}\)</span> is a sigma-algebra</li>
<li>Construct the extension on the new restriction</li>
<li>Learn about monotone classes</li>
<li>Prove the extension is unique via monotone classes</li>
<li>Look into “Extension of Caratheodori Extension Theorem”</li>
</ol>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Landim2016" class="csl-entry" role="listitem">
Landim, Claudio. 2016. <span>“Caratheodori Theorem.”</span> <a href="https://www.youtube.com/watch?v=ZNH4eDM7cJo" class="uri">https://www.youtube.com/watch?v=ZNH4eDM7cJo</a>.
</div>
<div id="ref-Lawrence2012" class="csl-entry" role="listitem">
Lawrence, Evans. 2012. <span>“Why Measure Theory for Probability?”</span> <a href="https://www.youtube.com/watch?v=rAYA2Mu51bw" class="uri">https://www.youtube.com/watch?v=rAYA2Mu51bw</a>.
</div>
<div id="ref-McElreath" class="csl-entry" role="listitem">
McElreath, Richard. 2015. <em>Statistical Rethinking: A Bayesian Course with Examples in r and Stan</em>. Second. CRC.
</div>
<div id="ref-Bizovi" class="csl-entry" role="listitem">
Mihai, Bizovi. 2017. <span>“Stochastic Modeling and Bayesian Inference.”</span> ASE.
</div>
<div id="ref-Rosenthal2006" class="csl-entry" role="listitem">
Rhosental, Jeffrey S. 2006. <em>First Look at Rigorous Probability Theory</em>. Second. World Scientific.
</div>
<div id="ref-Ruxanda2011" class="csl-entry" role="listitem">
Ruxanda, Gheorghe. 2011. <span>“Consideratii Privind Abordarea Stochastica in Domeniul Economic.”</span> <a href="http://doccent.ase.ro/media/20111108_Abordarea_Cantitativa_Stochastica.pdfs" class="uri">http://doccent.ase.ro/media/20111108_Abordarea_Cantitativa_Stochastica.pdfs</a>.
</div>
<div id="ref-Ruxanda2017" class="csl-entry" role="listitem">
———. 2017. <span>“Probability Theory and Stochastic Modeling.”</span> Lecture.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/blog\.economic-cybernetics\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>