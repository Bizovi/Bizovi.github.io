---
title: "R Tutorials for Behavioral Economics Class"
author: "Bizovi Mihai"
date: "2017-11-22"
output: html_document
tags: ["R", "behavioral-economics", "data-visualization"]
---



<p>In the last blog post I took a bird’s eye (personal) perspective of R programming and suggested not to be discouraged by early encounters with this seemingly weird language. The conclusion was that by following “the right tool for the right job” principle, R is a great language for statistical research and the ecosystem of packages improves the data analysis workflow and gives the modeler more tools to extract insights from data.</p>
<blockquote>
<p>What is the link to Behavioral Economics? R will be used (in class) as a tool for exploring domain-specific data in order to make informed decisions, fitting different kinds of models and validating the intuition from readings like Tversky &amp; Kahneman, Thaler on real data.</p>
</blockquote>
<div id="a-tutorial-on-metropolitan-area-housing" class="section level2">
<h2>A tutorial on Metropolitan Area Housing</h2>
<pre class="r"><code>library(tidyverse) # the ecosystem of data processing tools
library(tidyr)     # useful for getting the data in short-long formats
library(reshape2)  # for the function melt (long format data)
library(glue)      # string formatting
library(assertive) # assertions (active tests)
library(ochRe)     # stunning color palettes
library(readxl)    # read from excel spreadsheets</code></pre>
<pre class="r"><code>data &lt;- read_excel(&quot;data/landdata-msas-2016q1.xls&quot;, skip = 1)
data &lt;- data %&gt;% 
  mutate(MSA = as.factor(MSA), 
         Date = zoo::as.yearqtr(Date, format = &quot;%YQ%q&quot;)
         ) %&gt;%
  dplyr::rename(home_value = `Home Value`, 
                structure_cost = `Structure Cost`, 
                land_value = `Land Value`, 
                land_share = `Land Share (Pct)`, 
                home_pi = `Home Price Index`, 
                land_pi = `Land Price Index`
                )
data %&gt;% head()</code></pre>
<pre><code>## # A tibble: 6 x 8
##       MSA          Date home_value structure_cost land_value land_share
##    &lt;fctr&gt; &lt;S3: yearqtr&gt;      &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1 ATLANTA       1984 Q4   92856.39       67112.34   25744.05  0.2772459
## 2 ATLANTA       1985 Q1   93044.12       67826.46   25217.66  0.2710291
## 3 ATLANTA       1985 Q2   93269.26       68444.29   24824.97  0.2661646
## 4 ATLANTA       1985 Q3   97490.47       69026.93   28463.55  0.2919623
## 5 ATLANTA       1985 Q4   98809.50       69562.32   29247.18  0.2959956
## 6 ATLANTA       1986 Q1   99846.67       70078.32   29768.36  0.2981407
## # ... with 2 more variables: home_pi &lt;dbl&gt;, land_pi &lt;dbl&gt;</code></pre>
<pre class="r"><code>ny &lt;- data %&gt;% dplyr::filter(MSA == &quot;NEWYORK&quot;) 
ny %&gt;% 
  tidyr::gather(key = variable, value = value, -c(MSA, Date)) %&gt;% 
  dplyr::select(-MSA) %&gt;% 
  ggplot(aes(x = value, fill = variable)) + 
  geom_histogram(alpha = 0.5) + 
  facet_wrap(~ variable, scale = &quot;free&quot;) + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + 
  labs(y = &quot;Frequency&quot;, title = &quot;Distributions of the variables for NY&quot;) + 
  theme(legend.position = &quot;none&quot;) + 
  scale_fill_ochre(palette = &quot;nolan_ned&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/post/2017-11-18-r-tutorial-behavioral-economics-2_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="plotting-theoretical-utility-and-value-functions" class="section level2">
<h2>Plotting theoretical Utility and Value functions</h2>
<p>Hyperbolic Absolute Risk Aversion (Linear Risk Tolerance) is a class of utility functions, that can easily describe the particular cases of Constant Absolute Risk Aversion (CARA) and Constant Relative Risk Aversion (CRRA). <span class="math display">\[U(x;\gamma,a,b) = \frac{1 - \gamma}{\gamma}\bigg( \frac{ax}{1-\gamma} +b   \bigg) ^ \gamma\]</span> It is designed in such a way that the risk tolerance is linear <span class="math display">\[\tau(x)=-\frac{U&#39;(x)}{U&#39;&#39;(x)} = \frac{1}{1-\gamma}x + 
\frac{b}{a}
\]</span> where <span class="math inline">\(a &gt; 0\)</span> and <span class="math inline">\(\frac{ax}{1-\gamma} + b &gt; 0\)</span></p>
<p>The function tends to logarithmic if gamma tends to zero (by L’Hopital rule) and linear when goes to one. <span class="math display">\[U(x) \xrightarrow[\gamma \to 0]{} log(ax+b)\]</span></p>
<blockquote>
<p>The reason we’re going to overkill a simple plotting of HARA utility function is to showcase some important R concepts.</p>
</blockquote>
<p>First, we test user inputs via the <code>assertthat</code> package, which is a first step moving from manual validation to more automated methods of code testing. This doesn’t kick in when doing an exploratory analysis, but hopefully when starting to build Packages, learning how to test code in R<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> will pay off.</p>
<pre class="r"><code>hara &lt;- function(x, a, b, gamma) {
  # check that inputs to the function are good
  # using assetthat package
  assert_all_are_non_negative(x)
  assert_all_are_greater_than(x = a * x / (1 - gamma) + b, y = 0)
  assert_all_are_true(
    c(    
      is_positive(a), 
      is_not_equal_to(a, 0), 
      is_in_range(gamma, lower = 0, upper = 1)
      )
  )
  
  # return the function itself
  return(
    ((1 - gamma) / gamma) * (a * x / (1 - gamma) + b)^gamma
  )
}</code></pre>
<p>Second, we want to run the function a number of times by varying a parameter. The first idea of would be to write a for loop, but there is a more elegant way. The apply family of functions allows to run a function on elements of objects like lists. In this particular case I used a <code>sapply</code> function which returns a data frame with a column for values of function given a parameter.</p>
<pre class="r"><code># check if the function returns expected values
# hara(x = 1:20, a = 36, b = 52, gamma = 0.5)

gammas &lt;- c(0.5, 0.4, 0.3, 0.25, 0.1)
a &lt;- 36 # the functions start to look more linear as a is small
b &lt;- 52 

# apply the function on using 4 different gamma parameters
df &lt;- sapply(X = gammas, FUN = hara, x = 0:30,  a = a, b = b) %&gt;% 
  as_tibble()
# add the appropriate values to column names
colnames(df) &lt;- as.character(gammas)</code></pre>
<p>Third, we use the tidy way of data processing by heavily relying on the pipe operator <code>%&gt;%</code>, which passes an output of a function or an object to the next one. This makes the code much more readable and shows its power in Exploratory Data Analysis. The concept of Tidy Data<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> is inspired from relational databases and in order to use R eficiently one needs to understand the use-cases for long and wide data formats, what classifies as tidy.</p>
<p>The fourth point is that using <code>ggplot2</code> as the go-to visualization tool is not harder or more advanced, but simpler! Once you understand the <code>grammar of graphics</code><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> you get an incredibly general tool for data visualization, in which you can do stunning graphs with very little effort once you get the data into the right format.</p>
<pre class="r"><code>df %&gt;% 
  mutate(x = 1:nrow(df)) %&gt;% 
  reshape2::melt(id.vars = &quot;x&quot;) %&gt;% # could use tidyr::gather as an alternative
  rename(gamma = variable) %&gt;%
  ggplot(aes(x = x, y = value, color = gamma)) + 
  geom_line(size = 1) + 
  theme_minimal() + 
  labs(title = &quot;Hyperbolic Absolute Risk Aversion function&quot;, 
       subtitle = glue(&quot;with hyperparameters a = {a}, b = {b}&quot;)) + 
  scale_color_ochre(palette = &quot;nolan_ned&quot;) # if you feel fancy today</code></pre>
<p><img src="/post/2017-11-18-r-tutorial-behavioral-economics-2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>## Explain what is a color palette and why is it useful</code></pre>
</div>
<div id="a-tutorial-on-analysis-of-returns-and-investment-decisions" class="section level2">
<h2>A tutorial on Analysis of Returns and Investment Decisions</h2>
<!--

```r
library(tidyquant) # tidy data analysis and financial data interfacing
```


```r
# get stock prices for seven years using the Yahoo Finance API
stocks <- c("ORCL", "FSLR", "AMZN", "GOOG", "GE") %>% tq_get(
  get  = "stock.prices", 
  from = "2010-01-01", 
  to   = "2017-10-30"
)

# calculate the monthly returns
monthly.returns <- stocks %>% 
  group_by(symbol) %>% 
  tq_transmute(
    select     = adjusted, # column to calculate returns from 
    mutate_fun = periodReturn, # function from quantmod
    period     = "monthly",    # alternatively, "weekly" or daily
    col_rename = "return")

# need to compare against a general price index
baseline <- "SPX" %>%
    tq_get(
      get  = "stock.prices",
      from = "2010-01-01",
      to   = "2017-10-30") 


monthly.baseline <- baseline %>%
    tq_transmute(
      select     = adjusted, 
      mutate_fun = periodReturn, 
      period     = "monthly", 
      col_rename = "base.returns")
```

```
## Warning in to_period(xx, period = on.opts[[period]], ...): missing values
## removed from data
```


```r
# In order to perserve some information when averaging at monthly level, it would be great to represent the uncecrtainty

custom_stat_fun <- function(x, na.rm = TRUE, ...) {
    # ...   = additional arguments
    c(mean    = mean(x, na.rm = na.rm),
      stdev   = sd(x, na.rm = na.rm),
      quantile(x, na.rm = na.rm, ...)) 
}

# quantiles
pr <- c(0, 0.025, 0.25, 0.5, 0.75, 0.975, 1)

# Applying the custom function by week
monthly_returns <- stocks %>%
  group_by(symbol) %>%
    tq_transmute(
        select = close,
        mutate_fun = apply.monthly, 
        FUN = custom_stat_fun,
        na.rm = TRUE,
        probs = pr
    )

monthly_returns %>%
    ggplot(aes(x = date, y = `50%`, color = symbol)) +
    geom_ribbon(aes(ymin = `25%`, ymax = `75%`), 
                color = NA, fill = palette_light()[[1]], alpha = 0.3) +
    geom_point() +
    geom_vline(xintercept = as.Date(c("2011-09-01", "2012-07-01", 
                                      "2013-07-01", "2014-02-01", 
                                      "2015-01-01", "2016-02-01")), 
               lty = 2, color = "grey40") + 
    geom_ma(n = 5, size = 1, color = "steelblue2", lty = 1) + 
    facet_wrap(~ symbol, ncol = 2, scale = "free_y") +
    labs(title = "Standard and Poor's Average Monthly Price", x = "",
         subtitle = "Volatility shown as 1st and 3rd quantiles",
         y = "Price (k$)") +
  #  expand_limits(y = 50) + 
    scale_color_ochre(palette = "lorikeet") +
    theme_bw() + 
  theme(legend.position = "none")
```

<img src="/post/2017-11-18-r-tutorial-behavioral-economics-2_files/figure-html/unnamed-chunk-9-1.png" width="672" />

-->
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Testing R Code <a href="http://r-pkgs.had.co.nz/tests.html" class="uri">http://r-pkgs.had.co.nz/tests.html</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Hadley Wickham’s R for Data Science <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Paper on the grammar of Graphics <a href="http://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf" class="uri">http://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf</a><a href="#fnref3">↩</a></p></li>
</ol>
</div>
